# ğŸ“˜ EvaluaciÃ³n Modular â€” MÃ³dulo 5: Scoring Crediticio con Interpretabilidad

Este proyecto construye un modelo de clasificaciÃ³n binaria para predecir la probabilidad de buen comportamiento crediticio y, al mismo tiempo, garantizar la interpretabilidad del modelo mediante herramientas de anÃ¡lisis como SHAP.

---

## ğŸ“Œ CaracterÃ­sticas del proyecto

- Dataset: `credit-g` (OpenML)
- Tarea: ClasificaciÃ³n binaria (`good` vs `bad`)
- Modelo aplicado:
  - RegresiÃ³n LogÃ­stica con regularizaciÃ³n L1 (Lasso)
- Interpretabilidad:
  - VisualizaciÃ³n de importancia de variables con SHAP
- EvaluaciÃ³n del modelo:
  - Accuracy
  - Precision
  - Recall
  - F1-Score
  - AUC
  - Matriz de confusiÃ³n
- Visualizaciones:
  - Matriz de confusiÃ³n (`matriz_confusion.png`)
  - SHAP summary plot (`shap_summary_plot.png`)
- Tiempo de ejecuciÃ³n reportado

---

## ğŸ§ª MÃ©tricas obtenidas

```
Accuracy: 0.8050
Precision: 0.8400
Recall: 0.8936
F1 Score: 0.8660
AUC: 0.8188
Tiempo total de ejecuciÃ³n: 0.40 segundos
```

---

## ğŸ“ Estructura del proyecto

```
evaluacion_modulo5/
â”œâ”€â”€ principal.py                # CÃ³digo principal completo y comentado
â”œâ”€â”€ readme.md                   # Este documento
â”œâ”€â”€ requirements.txt            # LibrerÃ­as utilizadas
â”œâ”€â”€ capturas_terminal.txt       # Registro de ejecuciÃ³n
â”œâ”€â”€ matriz_confusion.png        # Matriz de confusiÃ³n
â”œâ”€â”€ shap_summary_plot.png       # VisualizaciÃ³n SHAP global
```

---

## ğŸ“Š InterpretaciÃ³n de resultados

- El modelo alcanzÃ³ un F1 Score de **0.866**, lo que representa un equilibrio adecuado entre precisiÃ³n y exhaustividad.
- El **recall de 0.8936** indica una muy buena capacidad de identificar correctamente los casos positivos (clientes buenos).
- La **AUC de 0.8188** refleja una sÃ³lida capacidad discriminativa del modelo.

---

## ğŸ§  AnÃ¡lisis de interpretabilidad

- Se utilizÃ³ **SHAP (SHapley Additive exPlanations)** para interpretar el modelo.
- El grÃ¡fico `shap_summary_plot.png` muestra quÃ© variables tienen mayor impacto positivo o negativo sobre la probabilidad de que un cliente sea "good".
- Dado que se utilizÃ³ Lasso, algunas variables con bajo aporte fueron descartadas automÃ¡ticamente (coeficiente = 0).

---

## ğŸ’¡ ReflexiÃ³n final

- El modelo entrega mÃ©tricas robustas con alta interpretabilidad, ideal para entornos donde las decisiones deben ser justificadas.
- La elecciÃ³n de regresiÃ³n logÃ­stica con regularizaciÃ³n L1 permite un modelo explicativo, compacto y confiable.
- SHAP aporta valor al traducir los coeficientes a un lenguaje visual y comprensible.

**En resumen:** se logrÃ³ un modelo predictivo sÃ³lido, interpretable y alineado con las exigencias del mÃ³dulo y la prÃ¡ctica profesional.

---

## ğŸ‘¤ Autor

Este proyecto fue desarrollado por RubÃ©n Schnettler.  
ViÃ±a del Mar, Chile.

## ğŸ¤– Asistencia tÃ©cnica

Apoyo en estructuraciÃ³n y documentaciÃ³n por:  
ChatGPT (gpt-4o, 2025).
