# ğŸ“˜ actividad sesiÃ³n 2 --- preprocesamiento (spaCy/NLTK) + tf-idf en notas clÃ­nicas

este proyecto aplica un **pipeline clÃ¡sico de nlp** sobre un corpus breve de notas clÃ­nicas.
se realiza **limpieza**, **tokenizaciÃ³n y lematizaciÃ³n/stemming**, eliminaciÃ³n de **stopwords**,
y se vectoriza con **tf-idf** (hasta bi-gramas). se visualizan **tÃ©rminos mÃ¡s relevantes por documento**
y se compara **corpus original vs preprocesado** mediante mÃ©tricas simples (longitud media, vocabulario, ttr).

---

## â–¶ï¸ ejecuciÃ³n rÃ¡pida

```bash
python principal.py
```

- genera todas las salidas en `resultados_sesion2/`.  
- acepta un `.txt` propio con un documento por lÃ­nea mediante `--corpus_txt`.  
- usa **spaCy** si el modelo `es_core_news_sm` estÃ¡ disponible; en caso contrario, **fallback** con **NLTK/regex**.  

---

## ğŸ“¦ estructura del proyecto

```
actividad2_modulo8/
â”œâ”€â”€ principal.py
â”œâ”€â”€ readme.md
â””â”€â”€ resultados_sesion2/
    â”œâ”€â”€ comparacion_original_vs_preprocesado.png
    â”œâ”€â”€ top_terminos_doc_0.png
    â”œâ”€â”€ top_terminos_doc_1.png
    â”œâ”€â”€ top_terminos_doc_2.png
    â”œâ”€â”€ tfidf_matrix_shape.txt
    â”œâ”€â”€ vocabulario.json
    â”œâ”€â”€ corpus_limpio.json
    â””â”€â”€ resumen.json
```

---

## 1) dataset y preprocesamiento

- **dataset**: 10 notas clÃ­nicas simuladas.  
- **limpieza**: minÃºsculas, remociÃ³n de eâ€‘mails, urls, nÃºmeros aislados y signos de puntuaciÃ³n.  
- **tokenizaciÃ³n y lematizaciÃ³n/stemming**: intenta **spaCy**; si no estÃ¡ disponible, usa **NLTK**.  
- **stopwords**: de spaCy o NLTK; si fallan, conjunto mÃ­nimo de respaldo.  
- **vectorizaciÃ³n**: **TFâ€‘IDF** con nâ€‘gramas (1â€“2).  

segÃºn `resumen.json`, el entorno usÃ³ fallback ( `spacy_activado = false` ).

---

## 2) resultados obtenidos

### dimensiones de matrices

- `tfidf` = **10 Ã— 77â€“208** segÃºn vocabulario final (ver `tfidf_matrix_shape.txt` y `vocabulario.json`).  

### comparaciÃ³n corpus (original vs preprocesado)

- **longitud media por documento**: **13.8 â†’ 9.9**  
- **tamaÃ±o de vocabulario**: **97 â†’ 77**  
- **typeâ€‘token ratio (ttr)**: **0.703 â†’ 0.778**  (aumenta distintividad relativa)  

(ver `comparacion_original_vs_preprocesado.png` y `resumen.json`).

### tÃ©rminos mÃ¡s relevantes (ejemplos)

- `doc0`: infecciÃ³n, congestiÃ³n, nasal, sospecha, viralâ€¦  
- `doc1`: abdominal, historial, persistente, gastritis, femeninaâ€¦  
- `doc2`: saturaciÃ³n, disnea, tÃ³rax, radiografÃ­a, covidâ€¦  

(ver `top_terminos_doc_*.png`).

---

## 3) anÃ¡lisis

- el **preprocesamiento** reduce ruido (nÃºmeros, conectores y signos), lo que se refleja en la caÃ­da de
  **longitud media** (13.8â†’9.9) y **vocabulario** (97â†’77). pese a tener menos tokens, la **ttr sube**
  (0.703â†’0.778), indicando mayor **densidad informativa** por palabra.  
- los **tÃ©rminos top por documento** capturan entidades/sÃ­ntomas clave (p. ej. *gastritis*, *radiografÃ­a*, *covid*),
  Ãºtiles para **bÃºsqueda semÃ¡ntica simple**, **agrupaciÃ³n** o como rasgos para **clasificadores**.  
- el fallback con **NLTK** mantiene el flujo cuando spaCy no estÃ¡ disponible, conservando resultados coherentes
  para un **baseline** reproducible y liviano.  

---

## 4) conclusiÃ³n

- se cumple el objetivo de **preprocesar** y **vectorizar** un corpus clÃ­nico corto con TFâ€‘IDF, generando
  artefactos interpretables y listos para siguientes tareas (clustering/clasificaciÃ³n).  
- el pipeline mejora la **seÃ±al semÃ¡ntica** al eliminar ruido y concentrar tÃ©rminos relevantes; esto se evidencia
  en el aumento del **TTR** y en la claridad de los **tÃ©rminos top**.  
- para una siguiente iteraciÃ³n se sugiere:
  - habilitar **spaCy** con `es_core_news_sm` para una **lematizaciÃ³n** mÃ¡s precisa.  
  - extender a **triâ€‘gramas** o agregar un **diccionario mÃ©dico** de stopwords.  
  - comparar con **embeddings** (word2vec/fastText/BERT) para evaluar ganancias en tareas downstream.  

---

## ğŸ‘¤ autor

Este proyecto fue desarrollado por **rRubÃ©n Schnettler**  
ğŸ“ ViÃ±a del Mar, Chile.  

---

## ğŸ¤– asistencia tÃ©cnica

documentaciÃ³n y apoyo en redacciÃ³n por **chatgpt (gpt-5, 2025)**
