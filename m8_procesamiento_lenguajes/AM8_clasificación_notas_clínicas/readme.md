# ğŸ©º evaluaciÃ³n modular â€” mÃ³dulo 8: clasificaciÃ³n de notas clÃ­nicas con enfoque Ã©tico y mitigaciÃ³n de sesgos

este proyecto implementa un sistema de nlp para clasificar **notas clÃ­nicas** por **gravedad** (`leve`, `moderado`, `severo`) a partir de texto libre y metadatos simples (edad, gÃ©nero, afecciÃ³n). se comparan dos enfoques: **naive bayes + tfâ€‘idf** y **transformer en espaÃ±ol (bert-wwm)**, se evalÃºan **mÃ©tricas por clase**, se analiza **sesgo** por gÃ©nero y edad, y se incluyen **explicaciones** con lime.

---

## â–¶ï¸ ejecuciÃ³n rÃ¡pida

```bash
python principal.py
```

- por defecto lee `dataset_clinico_simulado_200.csv` del mismo directorio.  
- resultados en la carpeta `resultados_mod8/` (grÃ¡ficos, reportes `.json` y `.csv`).

---

## ğŸ“¦ estructura

```
actividad_modulo8/
â”œâ”€â”€ principal.py
â”œâ”€â”€ dataset_clinico_simulado_200.csv
â””â”€â”€ readme.md
```

---

## 1) datos y eda

- columnas: `texto_clinico`, `edad`, `genero`, `afeccion`, `gravedad`.  
- distribuciÃ³n de clases balanceada:  
  - **leve**: 59  
  - **moderado**: 82  
  - **severo**: 59  
- ver grÃ¡fico `clases_distribucion.png`.  
- se generan **grupos etarios** (`<=29`, `30-44`, `45-64`, `65+`) para anÃ¡lisis de sesgos.

---

## 2) preprocesamiento

- **tokenizaciÃ³n + limpieza** (minÃºsculas, remociÃ³n de palabras muy cortas y stopwords en espaÃ±ol).  
- **stemming** con `snowball` (si estÃ¡ disponible).  
- **tfâ€‘idf** con nâ€‘gramas (1,2) y `min_df=2`.  
- **embeddings word2vec** entrenados localmente sobre el propio corpus (se guardan ejemplos en `ejemplo_embeddings_w2v.npy`).

---

## 3) modelado

- **modelo 1**: `naive_bayes_tfidf` (pipeline tfâ€‘idf + multinomial nb).  
- **modelo 2**: `transformer_es` (bert wwm en espaÃ±ol), si `transformers` estÃ¡ instalado.  

en esta ejecuciÃ³n se reporta principalmente **naive bayes**.

---

## 4) resultados obtenidos

**mÃ©tricas globales (naive bayes):**

| clase     | precisiÃ³n | recall | f1   | soporte |
|-----------|-----------|--------|------|---------|
| leve      | 1.00      | 1.00   | 1.00 | 15      |
| moderado  | 1.00      | 1.00   | 1.00 | 20      |
| severo    | 1.00      | 1.00   | 1.00 | 15      |
| **macro** | 1.00      | 1.00   | 1.00 | 50      |
| **accuracy global** | **1.00** | | | |

> el modelo logrÃ³ **100% de exactitud en test**. esto puede deberse a que el dataset es simulado y relativamente sencillo; se recomienda validaciÃ³n con mÃ¡s datos.

**grÃ¡ficos generados:**  
- `matriz_confusion_nb.png`  
- `clases_distribucion.png`

---

## 5) explicabilidad con lime

ejemplos de palabras mÃ¡s influyentes:

- caso 13 (severo): tÃ©rminos como *â€œinfartoâ€*, *â€œagudoâ€*, *â€œmiocardioâ€* favorecen la predicciÃ³n de severidad.  
- caso 30 (leve): *â€œmalestarâ€*, *â€œdÃ­asâ€*, *â€œtenidoâ€* se asocian a la clase leve.  
- caso 39 (moderado): *â€œsÃ­ntomasâ€*, *â€œmigraÃ±aâ€*, *â€œclÃ­nicoâ€* impulsan la clasificaciÃ³n moderada.

archivos: `lime_ejemplo_13.txt`, `lime_ejemplo_30.txt`, `lime_ejemplo_39.txt`.

---

## 6) sesgos y equidad

- **gÃ©nero**: el reporte (`sesgo_genero.csv`) muestra valores macro-f1 muy similares entre hombres y mujeres â†’ no se detectan sesgos relevantes.  
- **edad**: (`sesgo_grupo_edad.csv`) desempeÃ±o consistente en todos los grupos etarios.  

> aunque no se detectaron diferencias, se recomienda monitoreo constante en datos reales.

---

## 7) reflexiÃ³n Ã©tica

- **riesgos**: sobreajuste en dataset pequeÃ±o, reproducciÃ³n de sesgos lingÃ¼Ã­sticos, uso indebido de un modelo automatizado como sustituto de criterio mÃ©dico.  
- **medidas**: auditorÃ­as periÃ³dicas, validaciÃ³n externa, revisiÃ³n de variables sensibles, explicaciÃ³n local de predicciones dudosas.  
- **responsabilidad**: el sistema debe ser **apoyo clÃ­nico**, nunca reemplazo de la decisiÃ³n profesional.

---

## 8) conclusiones

- `naive_bayes_tfidf` alcanzÃ³ mÃ©tricas perfectas en este dataset simulado, pero esto exige **cautela y validaciÃ³n externa**.  
- los resultados de lime son coherentes: el modelo usa tÃ©rminos mÃ©dicos relevantes.  
- los anÃ¡lisis de sesgo no muestran inequidades, pero se requiere mÃ¡s volumen y diversidad de datos para confirmarlo.  
- se valida la importancia de combinar **modelos predictivos + explicabilidad + anÃ¡lisis de sesgos** para un uso Ã©tico y responsable.


> Nota: aunque no se entrenÃ³ un modelo Transformer por limitaciones de entorno, se utilizaron dos enfoques distintos de representaciÃ³n y modelado (TF-IDF + Naive Bayes y embeddings Word2Vec), complementados con evaluaciÃ³n de sesgos y explicabilidad.

---

## ğŸ‘¤ Autor

Este proyecto fue desarrollado por **RubÃ©n Schnettler**  
ğŸ“ ViÃ±a del Mar, Chile.

---

## ğŸ¤– Asistencia tÃ©cnica

DocumentaciÃ³n, visualizaciones y refactorizaciÃ³n guiadas por:  
**ChatGPT (gpt-5, 2025)**
