# combinacion: loss=categorical_crossentropy, opt=sgd
test_accuracy: 0.8258
test_loss: 0.4980

classification_report:
              precision    recall  f1-score   support

           0     0.7659    0.8310    0.7971      1000
           1     0.9722    0.9430    0.9574      1000
           2     0.7243    0.7040    0.7140      1000
           3     0.8153    0.8610    0.8375      1000
           4     0.7005    0.7720    0.7345      1000
           5     0.9390    0.8770    0.9069      1000
           6     0.6198    0.4810    0.5417      1000
           7     0.8840    0.9070    0.8954      1000
           8     0.9137    0.9420    0.9276      1000
           9     0.8969    0.9400    0.9180      1000

    accuracy                         0.8258     10000
   macro avg     0.8232    0.8258    0.8230     10000
weighted avg     0.8232    0.8258    0.8230     10000

confusion_matrix:
[[831   5  11  58   4   1  70   0  20   0]
 [  4 943  13  32   5   0   1   0   2   0]
 [ 23   5 704  10 160   1  83   0  14   0]
 [ 34  11   8 861  39   1  43   0   3   0]
 [  0   3  98  41 772   1  79   0   6   0]
 [  1   0   0   1   0 877   0  65   8  48]
 [191   2 125  44 119   3 481   0  35   0]
 [  0   0   0   0   0  33   0 907   0  60]
 [  1   1  13   9   3   5  19   7 942   0]
 [  0   0   0   0   0  12   0  47   1 940]]