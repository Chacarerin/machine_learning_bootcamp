# ğŸ“˜ actividad sesiÃ³n 3 --- autoencoders (reconstrucciÃ³n y denoising) con mnist

este proyecto implementa **autoencoders densos** para la tarea de
reconstrucciÃ³n de imÃ¡genes y reducciÃ³n de ruido usando el dataset
**mnist** (dÃ­gitos manuscritos). se comparan dos enfoques:  
- un **autoencoder bÃ¡sico**, que aprende a reconstruir imÃ¡genes limpias.  
- un **autoencoder denoising**, que recibe entradas ruidosas y aprende a
recuperar la versiÃ³n original limpia.  

---

## â–¶ï¸ ejecuciÃ³n rÃ¡pida

```bash
python principal.py
```

- genera todas las salidas en `resultados_sesion3/`.  
- no requiere descarga manual de datos (usa `tf.keras.datasets.mnist`).  

---

## ğŸ“¦ estructura del proyecto

```
actividad3_modulo7/
â”œâ”€â”€ principal.py
â”œâ”€â”€ readme.md
â””â”€â”€ resultados_sesion3/
    â”œâ”€â”€ curvas_loss_basico.png
    â”œâ”€â”€ curvas_loss_denoising.png
    â”œâ”€â”€ reconstrucciones_basico.png
    â”œâ”€â”€ denoising_tripleta.png
    â”œâ”€â”€ informe_resultados.txt
    â”œâ”€â”€ metricas.json
    â”œâ”€â”€ modelo_basico_resumen.txt
    â”œâ”€â”€ modelo_denoising_resumen.txt
    â”œâ”€â”€ modelo_basico.keras
    â””â”€â”€ modelo_denoising.keras
```

---

## 1) dataset y preprocesamiento

- **dataset**: mnist (60.000 imÃ¡genes de entrenamiento y 10.000 de
  prueba).  
- **preprocesamiento**: normalizaciÃ³n de pÃ­xeles al rango [0,1] y
  re-formateo a vectores de tamaÃ±o 784.  
- para denoising, se aÃ±adiÃ³ **ruido gaussiano** con desviaciÃ³n estÃ¡ndar
  0.5 a las imÃ¡genes de entrada.  

---

## 2) resultados obtenidos

### autoencoder bÃ¡sico

- pÃ©rdida en test (bce) = **0.1589**  
- pÃ©rdida en test (mse) = **0.0308**  
- el modelo logra reconstrucciones fieles de las imÃ¡genes originales.  

(ver `curvas_loss_basico.png` y `reconstrucciones_basico.png`)

### autoencoder denoising âœ… (ligeramente mejor)

- pÃ©rdida en test (bce) = **0.1526**  
- pÃ©rdida en test (mse) = **0.0291**  
- el modelo reduce efectivamente el ruido y recupera imÃ¡genes claras.  

(ver `curvas_loss_denoising.png` y `denoising_tripleta.png`)

---

## 3) anÃ¡lisis

- **arquitectura**: ambos modelos comparten la misma estructura densa,
  con una capa de codificaciÃ³n (64 neuronas) y una decodificaciÃ³n
  simÃ©trica, sumando ~218k parÃ¡metros.  
- **curvas de entrenamiento**: se observa convergencia rÃ¡pida en pocas
  Ã©pocas. el uso de *early stopping* evitÃ³ sobreajuste y el `clipnorm`
  estabilizÃ³ los gradientes en apple silicon, lo que permitiÃ³ mantener
  pÃ©rdidas razonables y entrenamientos reproducibles.  
- **rendimiento cuantitativo**: el autoencoder denoising obtuvo valores
  de pÃ©rdida levemente inferiores (bce=0.1526 vs. 0.1589), lo cual
  confirma que entrenar con entradas ruidosas no perjudica el desempeÃ±o,
  sino que incluso mejora la generalizaciÃ³n.  
- **evaluaciÃ³n cualitativa**: las reconstrucciones del modelo bÃ¡sico son
  nÃ­tidas, pero el denoising demuestra un valor aÃ±adido: cuando se
  introducen imÃ¡genes contaminadas con ruido, las salidas resultan mÃ¡s
  claras y estables, preservando la morfologÃ­a de los dÃ­gitos.  
- **interpretaciÃ³n pedagÃ³gica**: este ejercicio muestra que los
  autoencoders no solo comprimen informaciÃ³n, sino que tambiÃ©n pueden
  aprender funciones Ãºtiles como la â€œlimpiezaâ€ de seÃ±ales, lo cual los
  hace aplicables en dominios reales como eliminaciÃ³n de ruido en audio
  o imÃ¡genes mÃ©dicas.  

---

## 4) conclusiÃ³n

- el **autoencoder bÃ¡sico** es un buen punto de partida y confirma la
  capacidad del modelo para representar de forma comprimida y luego
  reconstruir los dÃ­gitos. sin embargo, su objetivo estÃ¡ limitado a
  copiar imÃ¡genes limpias.  
- el **autoencoder denoising** resultÃ³ ganador, ya que mantiene un
  rendimiento muy cercano en reconstrucciÃ³n de imÃ¡genes limpias, pero
  ademÃ¡s aporta la capacidad de restaurar datos degradados. sus mÃ©tricas
  son ligeramente mejores y las visualizaciones confirman un resultado
  mÃ¡s robusto ante perturbaciones.  
- desde el punto de vista de aprendizaje profundo, esto demuestra la
  importancia de **entrenar con ejemplos difÃ­ciles** (en este caso,
  imÃ¡genes ruidosas) para lograr modelos mÃ¡s resilientes.  
- a futuro, se podrÃ­a explorar el uso de **autoencoders convolucionales
  (convnets)**, que aprovechan la estructura espacial de las imÃ¡genes y
  suelen producir resultados mucho mÃ¡s nÃ­tidos en tareas de denoising.
  tambiÃ©n es posible experimentar con tÃ©cnicas de regularizaciÃ³n
  (dropout, weight decay) o con capas de mayor profundidad para mejorar
  aÃºn mÃ¡s la generalizaciÃ³n.  

---

## ğŸ‘¤ autor

Este proyecto fue desarrollado por **RubÃ©n Schnettler**  
ğŸ“ ViÃ±a del Mar, Chile.  

---

## ğŸ¤– asistencia tÃ©cnica

documentaciÃ³n y apoyo en redacciÃ³n por **chatgpt (gpt-5, 2025)**
