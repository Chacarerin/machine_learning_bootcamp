# ğŸ“˜ actividad sesiÃ³n 5 --- cnn con regularizaciÃ³n y optimizaciÃ³n (cifar-10)

este proyecto implementa una **red neuronal convolucional (cnn) regularizada** para clasificar las
10 categorÃ­as del dataset **cifar-10**. se incorporan tÃ©cnicas de regularizaciÃ³n (**l2** y **dropout**),
ademÃ¡s de callbacks de optimizaciÃ³n (**early stopping**, **reduceLROnPlateau**), con el objetivo
de mejorar la generalizaciÃ³n y controlar el sobreajuste. tambiÃ©n se analiza la evoluciÃ³n del
**learning rate** durante el entrenamiento.

---

## â–¶ï¸ ejecuciÃ³n rÃ¡pida

```bash
python principal.py
```

- genera todas las salidas en `resultados_sesion5/`.  
- no requiere descarga manual de datos (usa `tf.keras.datasets.cifar10`).  
- permite ajustar hiperparÃ¡metros por lÃ­nea de comandos (`--optimizador`, `--lr`, `--l2`, `--dropout`, etc.).  

---

## ğŸ“¦ estructura del proyecto

```
actividad5_modulo7/
â”œâ”€â”€ principal.py
â”œâ”€â”€ readme.md
â””â”€â”€ resultados_sesion5/
    â”œâ”€â”€ curvas_entrenamiento.png
    â”œâ”€â”€ learning_rate.png
    â”œâ”€â”€ matriz_confusion.png
    â”œâ”€â”€ reporte_clasificacion.txt
    â”œâ”€â”€ resumen.json
    â”œâ”€â”€ modelo_cnn.keras
    â”œâ”€â”€ mejor_modelo.keras
    â””â”€â”€ modelo_resumen.txt
```

---

## 1) dataset y preprocesamiento

- **dataset**: cifar-10 (50.000 imÃ¡genes de entrenamiento y 10.000 de prueba en 10 clases).  
- **preprocesamiento**: normalizaciÃ³n de pÃ­xeles a rango [0,1].  
- **split de validaciÃ³n**: 10% del set de entrenamiento reservado para validaciÃ³n durante el aprendizaje.  

---

## 2) resultados obtenidos

- **test accuracy** = **0.8077**  
- **test loss** = **0.5964**  

(ver `resumen.json`)

### reporte de clasificaciÃ³n (extracto)

- clases con mejor desempeÃ±o:  
  - **auto**: precisiÃ³n = 0.93, recall = 0.90, f1 = 0.91  
  - **barco**: precisiÃ³n = 0.86, recall = 0.94, f1 = 0.90  
- clases mÃ¡s dÃ©biles:  
  - **gato**: precisiÃ³n = 0.76, recall = 0.56, f1 = 0.64  
  - **pÃ¡jaro**: precisiÃ³n = 0.78, recall = 0.66, f1 = 0.72  

(ver `reporte_clasificacion.txt`)

### visualizaciones

- `curvas_entrenamiento.png`: muestran una reducciÃ³n progresiva de pÃ©rdida y estabilizaciÃ³n en validaciÃ³n.  
- `learning_rate.png`: evidencia la disminuciÃ³n del lr gracias a *ReduceLROnPlateau*.  
- `matriz_confusion.png`: refleja un desempeÃ±o equilibrado, con mayor confusiÃ³n entre clases visualmente similares (p. ej. gato â†” perro, ciervo â†” caballo).  

---

## 3) anÃ¡lisis

- la cnn propuesta alcanzÃ³ un **80.7% de accuracy en test**, superando ampliamente a un clasificador aleatorio (10%) y mostrando un buen equilibrio entre clases.  
- las tÃ©cnicas de regularizaciÃ³n (**l2 y dropout**) ayudaron a evitar sobreajuste, como se aprecia en la cercanÃ­a entre curvas de entrenamiento y validaciÃ³n.  
- la dinÃ¡mica del **learning rate** confirma que la estrategia adaptativa permitiÃ³ seguir aprendiendo a lo largo de las Ã©pocas, aunque la precisiÃ³n se estabilizÃ³ cerca del 81%.  
- la matriz de confusiÃ³n resalta que las confusiones ocurren principalmente en clases con similitudes visuales, lo que indica que el modelo captura caracterÃ­sticas generales pero aÃºn le cuesta diferenciar detalles finos.  
- el rendimiento es competitivo para una cnn compacta, aunque todavÃ­a inferior a arquitecturas mÃ¡s profundas preentrenadas.  

---

## 4) conclusiÃ³n

- el objetivo de implementar una **cnn regularizada con callbacks de optimizaciÃ³n** se cumpliÃ³ de forma satisfactoria.  
- el modelo logra un **desempeÃ±o robusto (~81% de accuracy)**, con buena estabilidad en validaciÃ³n y control del sobreajuste.  
- las mÃ©tricas muestran fortalezas en clases bien definidas (autos, barcos) y debilidades en aquellas con alta variabilidad intra-clase (gatos, pÃ¡jaros).  
- para mejorar se recomienda:  
  - aumentar la profundidad de la red o probar arquitecturas preentrenadas (*transfer learning*).  
  - ampliar el nÃºmero de Ã©pocas con un *scheduler* mÃ¡s gradual.  
  - explorar tÃ©cnicas adicionales de aumento de datos para reforzar clases mÃ¡s complejas.  

en sÃ­ntesis, la actividad demuestra el impacto positivo de la **regularizaciÃ³n y el ajuste dinÃ¡mico de hiperparÃ¡metros** en redes convolucionales aplicadas a cifar-10.

---

## ğŸ‘¤ autor

este proyecto fue desarrollado por **RubÃ©n Schnettler**  
ğŸ“ ViÃ±a del Mar, Chile.  

---

## ğŸ¤– asistencia tÃ©cnica

documentaciÃ³n y apoyo en redacciÃ³n por **chatgpt (gpt-5, 2025)**
