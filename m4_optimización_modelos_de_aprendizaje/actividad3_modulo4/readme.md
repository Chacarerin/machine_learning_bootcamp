#  Optimizaci贸n Bayesiana en Clasificaci贸n M茅dica

Este proyecto implementa un modelo de clasificaci贸n binaria usando Random Forest para predecir la presencia de c谩ncer de mama. Se utilizan dos enfoques de optimizaci贸n bayesiana para ajustar hiperpar谩metros: Scikit-Optimize y Hyperopt, evaluando su impacto en el rendimiento y eficiencia del modelo.

##  Caracter铆sticas

- Uso del dataset de c谩ncer de mama (Scikit-learn)
- Escalado de variables con StandardScaler
- Divisi贸n de datos en entrenamiento y prueba (70/30)
- Entrenamiento de modelo base sin optimizaci贸n
- Optimizaci贸n de hiperpar谩metros con:
  - Scikit-Optimize (BayesSearchCV)
  - Hyperopt (TPE)
- Comparaci贸n de m茅tricas y tiempos de ejecuci贸n

##  Estructura del Proyecto

```
ACTIVIDAD3_MODULO4/
 principal.py               # Contiene todo el c贸digo del proyecto
 requirements.txt           # Paquetes utilizados
 captura_terminal.txt       # Evidencia de ejecuci贸n completa
 readme.md                  # Este archivo
```

##  Uso del Proyecto

1. Instalar dependencias:
pip install -r requirements.txt

2. Ejecutar el proyecto:
python principal.py

Este comando ejecuta todo el flujo del proyecto:
- Carga y escala los datos
- Entrena modelo base
- Aplica Scikit-Optimize y luego Hyperopt
- Muestra m茅tricas y tiempos de cada m茅todo

##  M茅tricas utilizadas

- F1 Score
- Tiempo de ejecuci贸n
- Classification Report

##  Dataset

Se utiliza el dataset load_breast_cancer de Scikit-learn, el cual contiene caracter铆sticas de im谩genes de tumores de mama y un indicador binario que clasifica como maligno o benigno.

##  Reflexi贸n final y an谩lisis comparativo

驴Cu谩l t茅cnica fue m谩s eficiente?  
Hyperopt fue significativamente m谩s r谩pida (menos de 3 segundos) en comparaci贸n con Scikit-Optimize (m谩s de 12 segundos), alcanzando el mismo F1-Score. Esto la convierte en una opci贸n m谩s eficiente para este tipo de problemas.

驴Cu谩l entreg贸 el mejor resultado?  
Ambas t茅cnicas entregaron exactamente el mismo F1-Score (0.9772), pero Scikit-Optimize tard贸 m谩s. En este caso, no hubo diferencia en calidad de modelo, solo en eficiencia.

驴Qu茅 aprendiste del proceso?  
Aprend铆 que distintas bibliotecas pueden implementar el mismo enfoque de optimizaci贸n con diferentes resultados en tiempo. Adem谩s, confirm茅 que la optimizaci贸n bayesiana es 煤til para reducir la cantidad de combinaciones necesarias y a煤n as铆 obtener un muy buen desempe帽o.

##  Autor

Este proyecto fue desarrollado por Rub茅n Schnettler.  
Vi帽a del Mar, Chile.

##  Asistencia T茅cnica

Optimizaci贸n de c贸digo y documentaci贸n proporcionada por:  
ChatGPT (gpt-4o, build 2025-07).