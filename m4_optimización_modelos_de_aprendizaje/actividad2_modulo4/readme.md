# ğŸ§ª ClasificaciÃ³n MÃ©dica con Ajuste de HiperparÃ¡metros

Este proyecto construye un modelo de clasificaciÃ³n para predecir la probabilidad de que un paciente tenga diabetes tipo II, utilizando el dataset *Pima Indians Diabetes*. Se entrena un modelo base con Random Forest y luego se aplican dos tÃ©cnicas de optimizaciÃ³n de hiperparÃ¡metros: **Grid Search** y **Random Search**. Finalmente, se comparan mÃ©tricas de rendimiento y tiempos de ejecuciÃ³n.

---

## ğŸš€ CaracterÃ­sticas

- Random Forest como modelo base
- Preprocesamiento con imputaciÃ³n, escalado y divisiÃ³n 70/30
- Ajuste de hiperparÃ¡metros con:
  - Grid Search (exploraciÃ³n exhaustiva)
  - Random Search (exploraciÃ³n aleatoria)
- EvaluaciÃ³n con mÃ©tricas estÃ¡ndar
- VisualizaciÃ³n comparativa y reporte de tiempos de entrenamiento

---

## ğŸ“‚ Estructura del Proyecto

```
ACTIVIDAD2_MODULO4/
â”‚
â”œâ”€â”€ modelo/
â”‚   â”œâ”€â”€ cargar_datos.py
â”‚   â”œâ”€â”€ preprocesamiento.py
â”‚   â”œâ”€â”€ modelo_base.py
â”‚   â”œâ”€â”€ ajuste_hiperparametros.py
â”‚   â”œâ”€â”€ evaluacion.py
â”‚   â””â”€â”€ visualizacion.py
â”‚
â”œâ”€â”€ principal.py                  # Ejecuta todo el flujo del proyecto
â”œâ”€â”€ requirements.txt              # Dependencias
â”œâ”€â”€ grafico_comparativo1.jpeg     # ComparaciÃ³n Accuracy y F1 Score
â”œâ”€â”€ grafico_comparativo2.jpeg     # Importancia de caracterÃ­sticas
â”œâ”€â”€ tiempos_entrenamiento.txt     # Tiempos de Grid y Random Search
â””â”€â”€ readme.md                     # Este archivo
```

---

## ğŸ“¥ Uso del Proyecto

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Ejecutar el flujo completo

```bash
python principal.py
```

Este comando:
- Carga y explora los datos
- Preprocesa: reemplazo de ceros, escalado, split 70/30
- Entrena modelo base
- Aplica Grid Search y Random Search
- EvalÃºa todos los modelos
- Genera comparaciones grÃ¡ficas
- Guarda mÃ©tricas y tiempos en archivos

---

## ğŸ“Š MÃ©tricas utilizadas

- **Accuracy**
- **F1 Score**
- **Recall**
- **AUC (Ãrea bajo la curva ROC)**

---

## ğŸ“ˆ Visualizaciones

1. `grafico_comparativo1.jpeg`: comparaciÃ³n visual entre Accuracy y F1 de los tres modelos.
2. `grafico_comparativo2.jpeg`: importancia de variables segÃºn el mejor modelo ajustado.

---

## ğŸ“š Dataset

Dataset utilizado:  
[Pima Indians Diabetes Dataset (CSV)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)

Este dataset contiene variables mÃ©dicas de pacientes mujeres y un indicador binario de si desarrollaron diabetes tipo II.

---

## ğŸ¤” ReflexiÃ³n final y anÃ¡lisis comparativo

Durante esta actividad se compararon dos mÃ©todos clÃ¡sicos de ajuste de hiperparÃ¡metros para el modelo Random Forest: Grid Search y Random Search. Ambos lograron mejorar el rendimiento respecto al modelo base, aunque con diferencias notables en tiempo y precisiÃ³n.

### â“ Â¿CuÃ¡l tÃ©cnica fue mÃ¡s eficiente?
**Random Search** fue mÃ¡s eficiente en tÃ©rminos de tiempo. TardÃ³ considerablemente menos que Grid Search, lo que es esperable ya que evalÃºa menos combinaciones.

### ğŸ† Â¿CuÃ¡l encontrÃ³ el mejor modelo?
**Grid Search** entregÃ³ el modelo con mejor desempeÃ±o general. AlcanzÃ³ una mayor precisiÃ³n y F1 Score, producto de una exploraciÃ³n mÃ¡s exhaustiva del espacio de hiperparÃ¡metros.

### ğŸ’¡ Â¿QuÃ© hubieras hecho diferente?
En una siguiente iteraciÃ³n habrÃ­a incluido **Optuna** para aplicar optimizaciÃ³n bayesiana, que suele ofrecer una mejor relaciÃ³n entre rendimiento y tiempo en datasets medianos o grandes. AdemÃ¡s, habrÃ­a aÃ±adido validaciÃ³n cruzada estratificada manualmente para asegurar balance en cada fold.

---

## ğŸ‘¤ Autor

Este proyecto fue desarrollado por **RubÃ©n Schnettler.** 
ViÃ±a del Mar, Chile.

---

## ğŸ¤– Asistencia TÃ©cnica

Asistencia en depuraciÃ³n de errores y documentaciÃ³n proporcionada por:  
**`ChatGPT (gpt-4o, build 2025-07)`**  

---