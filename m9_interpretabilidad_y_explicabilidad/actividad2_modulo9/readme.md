# üìò actividad sesi√≥n 2 --- explicabilidad local con LIME (opiniones cl√≠nicas)

este proyecto entrena un clasificador binario **TF‚ÄëIDF + LogisticRegression** y explica sus predicciones
con **LIME** sobre un conjunto breve de opiniones cl√≠nicas (0=negativo, 1=positivo). se generan
artefactos gr√°ficos (PNG/HTML) para ‚â•3 ejemplos del set de test.

---

## ‚ñ∂Ô∏è ejecuci√≥n r√°pida

```bash
python principal.py
```

- genera todas las salidas en `resultados_sesion2/`.  
- permite usar datos propios: `--csv opiniones.csv --col_texto texto --col_label label` o `--txt opiniones.txt`.  
- √≠ndices a explicar configurables con `--exp_indices` (por defecto: `0,1,2`).  

---

## üì¶ estructura del proyecto

```
actividad2_modulo9/
‚îú‚îÄ‚îÄ principal.py
‚îú‚îÄ‚îÄ readme.md
‚îî‚îÄ‚îÄ resultados_sesion2/
    ‚îú‚îÄ‚îÄ matriz_confusion.png
    ‚îú‚îÄ‚îÄ reporte_clasificacion.txt
    ‚îú‚îÄ‚îÄ lime_doc_0.png
    ‚îú‚îÄ‚îÄ lime_doc_0.html
    ‚îú‚îÄ‚îÄ lime_doc_1.png
    ‚îú‚îÄ‚îÄ lime_doc_1.html
    ‚îú‚îÄ‚îÄ lime_doc_2.png
    ‚îú‚îÄ‚îÄ lime_doc_2.html
    ‚îî‚îÄ‚îÄ resumen.json
```
> los nombres `lime_doc_*` dependen de los √≠ndices efectivamente explicados.

---

## 1) datos y modelo

- **n_total** = **15** | **train/test** = **10/5** (estratificado).  
- **modelo**: `TF-IDF(1..2) + LogisticRegression(C=2.0)`.  
- **LIME**: top **10** t√©rminos por explicaci√≥n.  
- **ejemplos explicados** (test): [0, 1, 2].  

---

## 2) resultados obtenidos

- **accuracy (test)** = **0.8000**  
- **reporte por clase (test)**: ver `reporte_clasificacion.txt`.  
  - negativo ‚Äî precision 0.6667, recall 1.0000, f1 0.8000 (soporte 2)  
  - positivo ‚Äî precision 1.0000, recall 0.6667, f1 0.8000 (soporte 3)  
- **matriz de confusi√≥n**: ver `matriz_confusion.png` (2 TN, 2 TP, 1 FN).  

---

## 3) an√°lisis

- el modelo base **TF‚ÄëIDF + LR** logra un desempe√±o **estable** en un set peque√±o (accuracy ‚âà0.80).  
  la **clase positivo** muestra menor *recall* (un falso negativo), mientras que **negativo** se recupera bien.  
- **LIME** evidencia qu√© tokens empujan la predicci√≥n en cada instancia. esto permite:  
  1) detectar t√©rminos ‚Äúgatillo‚Äù (p. ej., *excelente*, *p√©sima*, *r√°pido*, *demasiado*) que pueden sesgar,  
  2) depurar el preprocesamiento (stopwords del dominio, normalizaci√≥n de tildes/variantes), y  
  3) dise√±ar **reglas de negocio** (alertas cuando una palabra clave aparezca con alta contribuci√≥n).  
- las explicaciones en **HTML** son √∫tiles para revisi√≥n manual: colorean palabras por contribuci√≥n y
  facilitan la discusi√≥n con perfiles no t√©cnicos.  

---

## 4) conclusi√≥n

- se cumple el objetivo: **entrenar**, **evaluar** y **explicar localmente** con **LIME** al menos 3
  ejemplos de test, dejando artefactos reproducibles.  
- el an√°lisis sugiere dos l√≠neas de mejora:  
  - sintonizar **C** y ampliar n‚Äëgramas (**tri‚Äëgramas**) para capturar contexto;  
  - enriquecer el pipeline con **stopwords m√©dicas** y lematizaci√≥n, apuntando a aumentar el *recall* en positivo.  

---

## üë§ autor

este proyecto fue desarrollado por **Rub√©n Schnettler**  
üìç Vi√±a del Mar, Chile.  

---

## ü§ñ asistencia t√©cnica

documentaci√≥n y apoyo en redacci√≥n por **chatgpt (gpt-5, 2025)**
