# üìò actividad sesi√≥n 1 --- explicabilidad con LIME y SHAP (opiniones cl√≠nicas)

este proyecto entrena un clasificador binario **TF‚ÄëIDF + LogisticRegression** sobre un conjunto
de opiniones cl√≠nicas (positivo/negativo) y lo explica con **LIME** y **SHAP**. se generan
explicaciones para varias instancias de test y se comparan palabras destacadas por ambos m√©todos.

---

## ‚ñ∂Ô∏è ejecuci√≥n r√°pida

```bash
python principal.py
```

- genera todas las salidas en `resultados_sesion1/`.  
- permite usar datos propios v√≠a `--csv` (columnas `texto`, `label`) o `--txt` (`texto;label`).  
- √≠ndices a explicar configurables con `--exp_indices` (por defecto: `0,1,2`).  

---

## üì¶ estructura del proyecto

```
actividad1_modulo9/
‚îú‚îÄ‚îÄ principal.py
‚îú‚îÄ‚îÄ readme.md
‚îî‚îÄ‚îÄ resultados_sesion1/
    ‚îú‚îÄ‚îÄ matriz_confusion.png
    ‚îú‚îÄ‚îÄ reporte_clasificacion.txt
    ‚îú‚îÄ‚îÄ lime_doc_0.png
    ‚îú‚îÄ‚îÄ lime_doc_0.html
    ‚îú‚îÄ‚îÄ lime_doc_1.png
    ‚îú‚îÄ‚îÄ lime_doc_1.html
    ‚îú‚îÄ‚îÄ lime_doc_2.png
    ‚îú‚îÄ‚îÄ lime_doc_2.html
    ‚îú‚îÄ‚îÄ shap_bar_doc_0.png
    ‚îú‚îÄ‚îÄ shap_waterfall_doc_0.png
    ‚îú‚îÄ‚îÄ shap_text_doc_0.html
    ‚îú‚îÄ‚îÄ shap_bar_doc_1.png
    ‚îú‚îÄ‚îÄ shap_waterfall_doc_1.png
    ‚îú‚îÄ‚îÄ shap_text_doc_1.html
    ‚îú‚îÄ‚îÄ shap_bar_doc_2.png
    ‚îú‚îÄ‚îÄ shap_waterfall_doc_2.png
    ‚îú‚îÄ‚îÄ shap_text_doc_2.html
    ‚îî‚îÄ‚îÄ resumen.json
```

> nota: seg√∫n los √≠ndices efectivamente explicados, los nombres pueden variar.

---

## 1) datos y modelo

- **dataset**: opiniones cl√≠nicas simuladas (etiquetas 0=negativo, 1=positivo).  
- **modelo**: `TF‚ÄëIDF(uni/bi‚Äëgramas) + LogisticRegression(C=2.0, class_weight='balanced')`.  
- **split**: 70% train / 30% test con estratificaci√≥n.  

---

## 2) resultados obtenidos

- **accuracy (test)** ‚âà **0.80**  
- **reporte por clase** (test):  
  - **negativo** ‚Äî precision: **0.6667**, recall: **1.0000**, f1: **0.8000** (soporte: 2)  
  - **positivo** ‚Äî precision: **1.0000**, recall: **0.6667**, f1: **0.8000** (soporte: 3)  
- **promedios**: macro‚Äëavg (prec/rec/f1) = **0.8333/0.8333/0.8000**, weighted‚Äëavg f1 = **0.8000**.  

(ver `reporte_clasificacion.txt` y `matriz_confusion.png`).  

---

## 3) an√°lisis

- la **matriz de confusi√≥n** muestra buen recuerdo para la clase **negativo** y una p√©rdida de recall en
  **positivo** (1 falso negativo). la precisi√≥n de **positivo** es alta, lo que sugiere umbral conservador.  
- **LIME** destaca tokens espec√≠ficos que empujan la predicci√≥n; resulta √∫til para revisar t√©rminos que
  podr√≠an estar sesgando el modelo (p. ej., *excelente*, *p√©sima*, *r√°pido*, *demasiado*).  
- **SHAP** ofrece una descomposici√≥n aditiva: los **bar plots** priorizan contribuciones absolutas y los
  **waterfall** detallan c√≥mo cada t√©rmino ajusta la probabilidad final. la vista **text HTML** colorea
  palabras seg√∫n su impacto, ideal para auditor√≠as r√°pidas.  
- en la comparaci√≥n cualitativa, suele existir **intersecci√≥n** entre las palabras top de LIME y SHAP; las
  discrepancias ayudan a detectar **inestabilidad local** o efectos de multicolinealidad en n‚Äëgramas.  

---

## 4) conclusi√≥n

- se cumple el objetivo de **entrenar, evaluar y explicar** un clasificador de opiniones con **LIME** y
  **SHAP**, produciendo artefactos reproducibles y aptos para informe.  
- el desempe√±o (**80% de accuracy**) es coherente para un baseline TF‚ÄëIDF; las explicaciones permiten
  detectar **falsos negativos** y revisar vocabulario sensible.  
- siguientes pasos sugeridos:  
  - sintonizar **C** y **n‚Äëgramas**, incorporar **stopwords del dominio**.  
  - usar **calibraci√≥n** o ajuste de umbral para equilibrar *precision/recall* en **positivo**.  
  - comparar con modelos **transformer** (fine‚Äëtuning ligero) y validar si las explicaciones convergen.  

---

## üë§ autor

este proyecto fue desarrollado por **Rub√©n Schnettler**  
üìç Vi√±a del Mar, Chile.  

---

## ü§ñ asistencia t√©cnica

documentaci√≥n y apoyo en redacci√≥n por **chatgpt (gpt-5, 2025)**
